{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-03T14:32:02.488210Z",
     "start_time": "2024-07-03T14:32:02.467966Z"
    }
   },
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:32:02.692306Z",
     "start_time": "2024-07-03T14:32:02.663590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the landmarks data from the CSV file\n",
    "landmarks_df = pd.read_csv('hand_landmarks.csv')\n",
    "\n"
   ],
   "id": "f14b5188c972b5e7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:32:02.832434Z",
     "start_time": "2024-07-03T14:32:02.820216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract labels and features from landmarks data\n",
    "landmarks_labels = landmarks_df.iloc[:, 0].values\n",
    "landmarks_features = landmarks_df.iloc[:, 2:].values  # Should start from column number 3 (index 2)\n",
    "\n",
    "# Encode labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(landmarks_labels)\n",
    "\n",
    "# Convert encoded labels to categorical\n",
    "categorical_labels = tf.keras.utils.to_categorical(encoded_labels)\n",
    "\n"
   ],
   "id": "b08a047adce29308",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:32:03.005264Z",
     "start_time": "2024-07-03T14:32:02.984227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    landmarks_features, categorical_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display shapes of the resulting datasets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ],
   "id": "a6bfc6eaff075d31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (290, 84)\n",
      "X_test shape: (73, 84)\n",
      "y_train shape: (290, 1)\n",
      "y_test shape: (73, 1)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "84d94560b619b043"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:32:03.412396Z",
     "start_time": "2024-07-03T14:32:03.327091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the input layer\n",
    "input_layer = Input(shape=(84,), name='landmarks_input')\n",
    "\n",
    "# Define the model architecture\n",
    "x = Dense(64, activation='relu')(input_layer)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "output = Dense(categorical_labels.shape[1], activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ],
   "id": "7d5f1d1e71ca3583",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ landmarks_input (\u001B[38;5;33mInputLayer\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m84\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │         \u001B[38;5;34m5,440\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m2,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             │           \u001B[38;5;34m528\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m17\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ landmarks_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,440</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m8,065\u001B[0m (31.50 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,065</span> (31.50 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m8,065\u001B[0m (31.50 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,065</span> (31.50 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:32:05.834822Z",
     "start_time": "2024-07-03T14:32:03.521202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ],
   "id": "dfb98bc099f072c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarpa\\PycharmProjects\\BlanderAnimator\\.venv\\lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "C:\\Users\\sarpa\\PycharmProjects\\BlanderAnimator\\.venv\\lib\\site-packages\\keras\\src\\losses\\losses.py:27: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:32:06.808013Z",
     "start_time": "2024-07-03T14:32:05.836815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g', square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_true, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_true, y_pred)"
   ],
   "id": "157449ec9afda729",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 0.0000e+00 \n",
      "Test Loss: 0.0000, Test Accuracy: 1.0000\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarpa\\PycharmProjects\\BlanderAnimator\\.venv\\lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "C:\\Users\\sarpa\\PycharmProjects\\BlanderAnimator\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:395: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        73\n",
      "\n",
      "    accuracy                           1.00        73\n",
      "   macro avg       1.00      1.00      1.00        73\n",
      "weighted avg       1.00      1.00      1.00        73\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:32:06.870589Z",
     "start_time": "2024-07-03T14:32:06.808943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the model\n",
    "model.save(\"keypoint_classifier.hdf5\", include_optimizer=False)"
   ],
   "id": "6e2d2678fa50c423",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-03T14:32:06.872589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert the model to TensorFlow Lite format with quantization\n",
    "tflite_save_path = 'hand_gesture_model.tflite'\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model\n",
    "with open(tflite_save_path, 'wb') as f:\n",
    "    f.write(tflite_quantized_model)"
   ],
   "id": "ab197aa3f58f49b0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarpa\\PycharmProjects\\BlanderAnimator\\.venv\\lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\sarpa\\AppData\\Local\\Temp\\tmp1gjgvkiz\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\sarpa\\AppData\\Local\\Temp\\tmp1gjgvkiz\\assets\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference test with TensorFlow Lite model\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensor details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Set the input tensors\n",
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))\n",
    "\n",
    "# Perform inference\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# Print results\n",
    "print(\"TFLite Model Results:\", np.squeeze(tflite_results))\n",
    "print(\"Predicted Class:\", np.argmax(np.squeeze(tflite_results)))"
   ],
   "id": "129f5f4acbaa6a5e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
