{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T09:54:38.312283Z",
     "start_time": "2024-07-02T09:54:38.293288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow\n"
   ],
   "id": "69b652ad5243d24b",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T09:54:38.471284Z",
     "start_time": "2024-07-02T09:54:38.452284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the data from CSV files\n",
    "landmarks_df = pd.read_csv('landmarks.csv', header=None)\n",
    "point_history_df = pd.read_csv('point_history.csv', header=None)\n"
   ],
   "id": "71f875afc7fe40ed",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T09:54:38.645314Z",
     "start_time": "2024-07-02T09:54:38.610321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inspect the first few rows of the data\n",
    "print(\"Landmarks Data:\")\n",
    "print(landmarks_df.head())\n",
    "\n",
    "print(\"\\nPoint History Data:\")\n",
    "print(point_history_df.head())\n"
   ],
   "id": "1077f06a291382a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landmarks Data:\n",
      "     0    1    2         3         4         5         6         7         8   \\\n",
      "0  Time  0.0  0.0 -0.113674 -0.044264 -0.216580 -0.126220 -0.248445 -0.196120   \n",
      "1  Time  0.0  0.0 -0.114794 -0.043287 -0.214074 -0.123791 -0.246337 -0.193160   \n",
      "2  Time  0.0  0.0 -0.114696 -0.039556 -0.213406 -0.114329 -0.247248 -0.183603   \n",
      "3  Time  0.0  0.0 -0.123438 -0.051262 -0.224791 -0.130263 -0.271487 -0.208909   \n",
      "4  Time  0.0  0.0 -0.116346 -0.047808 -0.215962 -0.129154 -0.256723 -0.202200   \n",
      "\n",
      "         9   ...        75        76        77        78        79        80  \\\n",
      "0 -0.176292  ... -0.471061  0.850652 -0.831177  0.444402 -0.748317  0.565786   \n",
      "1 -0.176992  ... -0.459641  0.901476 -0.809044  0.456671 -0.709299  0.585428   \n",
      "2 -0.186922  ... -0.509290  0.909404 -0.798722  0.458317 -0.694875  0.607484   \n",
      "3 -0.216370  ... -0.672983  0.777412 -0.792451  0.470704 -0.692611  0.674606   \n",
      "4 -0.205062  ... -0.673209  0.752966 -0.785853  0.480925 -0.684251  0.691749   \n",
      "\n",
      "         81        82        83        84  \n",
      "0 -0.702489  0.686011 -0.678526  0.790652  \n",
      "1 -0.673417  0.706177 -0.657146  0.809652  \n",
      "2 -0.668170  0.730099 -0.661308  0.822499  \n",
      "3 -0.717501  0.759693 -0.747176  0.758167  \n",
      "4 -0.715061  0.763959 -0.744152  0.751711  \n",
      "\n",
      "[5 rows x 85 columns]\n",
      "\n",
      "Point History Data:\n",
      "     0    1    2         3         4         5         6         7         8   \\\n",
      "0  Time  0.0  0.0  0.014885 -0.320739  0.083628  0.039838  0.150141  0.076068   \n",
      "1  Time  0.0  0.0  0.017442 -0.319278  0.087491  0.055673  0.163967  0.083985   \n",
      "2  Time  0.0  0.0  0.013313 -0.333940  0.086047  0.050409  0.164192  0.092192   \n",
      "3  Time  0.0  0.0 -0.004279 -0.366085  0.076812  0.062935  0.156553  0.108376   \n",
      "4  Time  0.0  0.0 -0.004704 -0.390360  0.070589  0.056728  0.152538  0.098485   \n",
      "\n",
      "         9   ...        11        12        13        14        15        16  \\\n",
      "0  0.220987  ... -0.162548  0.978845 -0.030001  0.926346 -0.172728  1.000000   \n",
      "1  0.241407  ... -0.104226  0.930907 -0.015578  0.919453 -0.164264  1.000000   \n",
      "2  0.252952  ... -0.135751  0.934600 -0.050154  0.936893 -0.193893  1.000000   \n",
      "3  0.249991  ... -0.066126  1.000000 -0.174089  0.944436 -0.327002  0.963704   \n",
      "4  0.238958  ... -0.081813  1.000000 -0.213000  0.908707 -0.336813  0.912045   \n",
      "\n",
      "         17        18        19        20  \n",
      "0 -0.263165  0.935963 -0.448385  0.882397  \n",
      "1 -0.246350  0.959996 -0.418491  0.879965  \n",
      "2 -0.290671  0.995724 -0.427742  0.917364  \n",
      "3 -0.429137  0.949011 -0.498865  0.930924  \n",
      "4 -0.439018  0.906846 -0.505546  0.905669  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T09:54:38.802285Z",
     "start_time": "2024-07-02T09:54:38.790285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract labels and features from landmarks data\n",
    "landmarks_labels = landmarks_df.iloc[:, 0].values\n",
    "landmarks_features = landmarks_df.iloc[:, 1:].values\n",
    "\n",
    "# Extract labels and features from point history data\n",
    "point_history_labels = point_history_df.iloc[:, 0].values\n",
    "point_history_features = point_history_df.iloc[:, 1:].values\n",
    "\n",
    "# Ensure the labels are the same for both datasets\n",
    "assert np.array_equal(landmarks_labels, point_history_labels), \"Labels do not match between datasets.\"\n"
   ],
   "id": "9f89a225dcdf5660",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T09:54:38.944286Z",
     "start_time": "2024-07-02T09:54:38.927284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encode labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(landmarks_labels)\n",
    "\n",
    "# Convert encoded labels to categorical\n",
    "categorical_labels = tensorflow.keras.utils.to_categorical(encoded_labels)\n"
   ],
   "id": "27d1e56ab6ebd490",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T09:54:39.070288Z",
     "start_time": "2024-07-02T09:54:39.062288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data into training and test sets\n",
    "X_landmarks_train, X_landmarks_test, X_point_history_train, X_point_history_test, y_train, y_test = train_test_split(\n",
    "    landmarks_features, point_history_features, categorical_labels, test_size=0.2, random_state=42)\n"
   ],
   "id": "661146fb8299af20",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T09:54:39.212704Z",
     "start_time": "2024-07-02T09:54:39.194704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verify the shapes of the data\n",
    "print(\"X_landmarks_train shape:\", X_landmarks_train.shape)\n",
    "print(\"X_landmarks_test shape:\", X_landmarks_test.shape)\n",
    "print(\"X_point_history_train shape:\", X_point_history_train.shape)\n",
    "print(\"X_point_history_test shape:\", X_point_history_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ],
   "id": "3dc0845ceb97ed7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_landmarks_train shape: (212, 84)\n",
      "X_landmarks_test shape: (53, 84)\n",
      "X_point_history_train shape: (212, 20)\n",
      "X_point_history_test shape: (53, 20)\n",
      "y_train shape: (212, 3)\n",
      "y_test shape: (53, 3)\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T09:54:39.354309Z",
     "start_time": "2024-07-02T09:54:39.338164Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "92f697a961881ec5",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "6f5bede87cb1a7a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "875d523cddb6d94c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "940ab75c16ccf7bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T09:54:39.938639Z",
     "start_time": "2024-07-02T09:54:39.919644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ],
   "id": "fa757ec97606fead",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T09:54:40.177666Z",
     "start_time": "2024-07-02T09:54:40.083668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the input layers\n",
    "landmarks_input = Input(shape=(84,), name='landmarks_input')\n",
    "point_history_input = Input(shape=(20,), name='point_history_input')\n",
    "\n",
    "# Define the landmarks branch\n",
    "x = Dense(64, activation='relu')(landmarks_input)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "# Define the point history branch\n",
    "y = Dense(32, activation='relu')(point_history_input)\n",
    "y = Dense(16, activation='relu')(y)\n",
    "\n",
    "# Concatenate the branches\n",
    "combined = Concatenate()([x, y])\n",
    "\n",
    "# Output layer\n",
    "z = Dense(16, activation='relu')(combined)\n",
    "output = Dense(3, activation='softmax')(z)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Model(inputs=[landmarks_input, point_history_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ],
   "id": "d661cf9a56c50a94",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_2\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ landmarks_input     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m84\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ point_history_input │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │      \u001B[38;5;34m5,440\u001B[0m │ landmarks_input[\u001B[38;5;34m…\u001B[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │        \u001B[38;5;34m672\u001B[0m │ point_history_in… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │      \u001B[38;5;34m2,080\u001B[0m │ dense_12[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_15 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)        │        \u001B[38;5;34m528\u001B[0m │ dense_14[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m48\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ dense_13[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],   │\n",
       "│ (\u001B[38;5;33mConcatenate\u001B[0m)       │                   │            │ dense_15[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_16 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)        │        \u001B[38;5;34m784\u001B[0m │ concatenate_2[\u001B[38;5;34m0\u001B[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_17 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m)         │         \u001B[38;5;34m51\u001B[0m │ dense_16[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ landmarks_input     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ point_history_input │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,440</span> │ landmarks_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">672</span> │ point_history_in… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m9,555\u001B[0m (37.32 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,555</span> (37.32 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m9,555\u001B[0m (37.32 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,555</span> (37.32 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T09:54:49.746507Z",
     "start_time": "2024-07-02T09:54:40.269666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_landmarks_train, X_point_history_train], y_train,\n",
    "    validation_data=([X_landmarks_test, X_point_history_test], y_test),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ],
   "id": "966d04072611c62d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.3624 - loss: 1.0718 - val_accuracy: 0.9057 - val_loss: 0.9121\n",
      "Epoch 2/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.8723 - loss: 0.8777 - val_accuracy: 0.9245 - val_loss: 0.7592\n",
      "Epoch 3/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9210 - loss: 0.7386 - val_accuracy: 1.0000 - val_loss: 0.6544\n",
      "Epoch 4/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9392 - loss: 0.6147 - val_accuracy: 1.0000 - val_loss: 0.5504\n",
      "Epoch 5/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9697 - loss: 0.4969 - val_accuracy: 0.9811 - val_loss: 0.4454\n",
      "Epoch 6/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9265 - loss: 0.4293 - val_accuracy: 0.9623 - val_loss: 0.3573\n",
      "Epoch 7/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9366 - loss: 0.3502 - val_accuracy: 0.9623 - val_loss: 0.2818\n",
      "Epoch 8/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9744 - loss: 0.2626 - val_accuracy: 0.9623 - val_loss: 0.2214\n",
      "Epoch 9/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9644 - loss: 0.2046 - val_accuracy: 0.9623 - val_loss: 0.1781\n",
      "Epoch 10/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9679 - loss: 0.1576 - val_accuracy: 0.9623 - val_loss: 0.1421\n",
      "Epoch 11/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9851 - loss: 0.1019 - val_accuracy: 1.0000 - val_loss: 0.1002\n",
      "Epoch 12/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 1.0000 - loss: 0.0734 - val_accuracy: 0.9811 - val_loss: 0.0802\n",
      "Epoch 13/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9988 - loss: 0.0536 - val_accuracy: 0.9623 - val_loss: 0.0736\n",
      "Epoch 14/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0361 - val_accuracy: 1.0000 - val_loss: 0.0495\n",
      "Epoch 15/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 0.0295 - val_accuracy: 1.0000 - val_loss: 0.0394\n",
      "Epoch 16/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 0.0249 - val_accuracy: 1.0000 - val_loss: 0.0320\n",
      "Epoch 17/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 0.0215 - val_accuracy: 1.0000 - val_loss: 0.0300\n",
      "Epoch 18/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 1.0000 - val_loss: 0.0289\n",
      "Epoch 19/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 1.0000 - val_loss: 0.0250\n",
      "Epoch 20/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 0.0236\n",
      "Epoch 21/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 1.0000 - val_loss: 0.0223\n",
      "Epoch 22/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 0.0207\n",
      "Epoch 23/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 1.0000 - val_loss: 0.0187\n",
      "Epoch 24/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 0.0178\n",
      "Epoch 25/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 0.0172\n",
      "Epoch 26/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 0.0161\n",
      "Epoch 27/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 0.0154\n",
      "Epoch 28/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 0.0154\n",
      "Epoch 29/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0154\n",
      "Epoch 30/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0152\n",
      "Epoch 31/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 0.0127\n",
      "Epoch 32/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0121\n",
      "Epoch 33/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0122\n",
      "Epoch 34/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0124\n",
      "Epoch 35/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0124\n",
      "Epoch 36/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 0.0124\n",
      "Epoch 37/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0119\n",
      "Epoch 38/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0112\n",
      "Epoch 39/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0109\n",
      "Epoch 40/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0107\n",
      "Epoch 41/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0106\n",
      "Epoch 42/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0106\n",
      "Epoch 43/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0106\n",
      "Epoch 44/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0102\n",
      "Epoch 45/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0100\n",
      "Epoch 46/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 47/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 48/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0095\n",
      "Epoch 49/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0094\n",
      "Epoch 50/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0093\n",
      "Epoch 51/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0091\n",
      "Epoch 52/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 8.0254e-04 - val_accuracy: 1.0000 - val_loss: 0.0090\n",
      "Epoch 53/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0088\n",
      "Epoch 54/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 1.0000 - loss: 9.5014e-04 - val_accuracy: 1.0000 - val_loss: 0.0088\n",
      "Epoch 55/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 8.1248e-04 - val_accuracy: 1.0000 - val_loss: 0.0087\n",
      "Epoch 56/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 9.3331e-04 - val_accuracy: 1.0000 - val_loss: 0.0085\n",
      "Epoch 57/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 8.9755e-04 - val_accuracy: 1.0000 - val_loss: 0.0085\n",
      "Epoch 58/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 0.0083\n",
      "Epoch 59/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 9.7697e-04 - val_accuracy: 1.0000 - val_loss: 0.0084\n",
      "Epoch 60/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 6.7427e-04 - val_accuracy: 1.0000 - val_loss: 0.0079\n",
      "Epoch 61/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 8.1440e-04 - val_accuracy: 1.0000 - val_loss: 0.0079\n",
      "Epoch 62/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 7.0122e-04 - val_accuracy: 1.0000 - val_loss: 0.0078\n",
      "Epoch 63/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 5.8821e-04 - val_accuracy: 1.0000 - val_loss: 0.0077\n",
      "Epoch 64/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 7.2713e-04 - val_accuracy: 1.0000 - val_loss: 0.0076\n",
      "Epoch 65/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 6.6449e-04 - val_accuracy: 1.0000 - val_loss: 0.0074\n",
      "Epoch 66/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 6.5723e-04 - val_accuracy: 1.0000 - val_loss: 0.0074\n",
      "Epoch 67/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 6.0828e-04 - val_accuracy: 1.0000 - val_loss: 0.0073\n",
      "Epoch 68/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 5.5543e-04 - val_accuracy: 1.0000 - val_loss: 0.0073\n",
      "Epoch 69/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 7.1719e-04 - val_accuracy: 1.0000 - val_loss: 0.0073\n",
      "Epoch 70/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 5.2481e-04 - val_accuracy: 1.0000 - val_loss: 0.0072\n",
      "Epoch 71/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 5.5281e-04 - val_accuracy: 1.0000 - val_loss: 0.0072\n",
      "Epoch 72/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 5.1313e-04 - val_accuracy: 1.0000 - val_loss: 0.0072\n",
      "Epoch 73/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 5.6688e-04 - val_accuracy: 1.0000 - val_loss: 0.0071\n",
      "Epoch 74/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 4.9513e-04 - val_accuracy: 1.0000 - val_loss: 0.0070\n",
      "Epoch 75/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 4.4144e-04 - val_accuracy: 1.0000 - val_loss: 0.0069\n",
      "Epoch 76/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 4.4789e-04 - val_accuracy: 1.0000 - val_loss: 0.0069\n",
      "Epoch 77/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 4.1125e-04 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
      "Epoch 78/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 5.7102e-04 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
      "Epoch 79/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 4.5265e-04 - val_accuracy: 1.0000 - val_loss: 0.0065\n",
      "Epoch 80/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 3.7664e-04 - val_accuracy: 1.0000 - val_loss: 0.0063\n",
      "Epoch 81/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 5.0395e-04 - val_accuracy: 1.0000 - val_loss: 0.0063\n",
      "Epoch 82/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 4.3226e-04 - val_accuracy: 1.0000 - val_loss: 0.0064\n",
      "Epoch 83/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 4.0806e-04 - val_accuracy: 1.0000 - val_loss: 0.0063\n",
      "Epoch 84/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 2.9218e-04 - val_accuracy: 1.0000 - val_loss: 0.0063\n",
      "Epoch 85/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 3.9907e-04 - val_accuracy: 1.0000 - val_loss: 0.0062\n",
      "Epoch 86/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 3.9752e-04 - val_accuracy: 1.0000 - val_loss: 0.0062\n",
      "Epoch 87/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 3.2259e-04 - val_accuracy: 1.0000 - val_loss: 0.0061\n",
      "Epoch 88/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 1.0000 - loss: 2.9620e-04 - val_accuracy: 1.0000 - val_loss: 0.0061\n",
      "Epoch 89/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 3.2416e-04 - val_accuracy: 1.0000 - val_loss: 0.0061\n",
      "Epoch 90/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 3.2890e-04 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
      "Epoch 91/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 3.0859e-04 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
      "Epoch 92/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 3.0939e-04 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
      "Epoch 93/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 1.0000 - loss: 3.4692e-04 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
      "Epoch 94/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 2.9636e-04 - val_accuracy: 1.0000 - val_loss: 0.0058\n",
      "Epoch 95/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 2.9447e-04 - val_accuracy: 1.0000 - val_loss: 0.0057\n",
      "Epoch 96/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 2.8805e-04 - val_accuracy: 1.0000 - val_loss: 0.0057\n",
      "Epoch 97/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 1.0000 - loss: 2.5703e-04 - val_accuracy: 1.0000 - val_loss: 0.0057\n",
      "Epoch 98/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 3.1230e-04 - val_accuracy: 1.0000 - val_loss: 0.0057\n",
      "Epoch 99/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 2.7679e-04 - val_accuracy: 1.0000 - val_loss: 0.0057\n",
      "Epoch 100/100\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 2.4729e-04 - val_accuracy: 1.0000 - val_loss: 0.0056\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T09:54:50.095398Z",
     "start_time": "2024-07-02T09:54:49.748511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss, accuracy = model.evaluate([X_landmarks_test, X_point_history_test], y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_true, y_pred))\n",
    "\n",
    "Y_pred = model.predict([X_landmarks_test, X_point_history_test])\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_true, y_pred)\n"
   ],
   "id": "3c1268b62081b81b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 0.0068 \n",
      "Test Loss: 0.0056, Test Accuracy: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001BF5F564280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001BF5F564280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 68ms/stepWARNING:tensorflow:6 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001BF5F564280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001BF5F564280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           2       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           1.00        53\n",
      "   macro avg       1.00      1.00      1.00        53\n",
      "weighted avg       1.00      1.00      1.00        53\n",
      "\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T09:54:50.127003Z",
     "start_time": "2024-07-02T09:54:50.096391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the model\n",
    "# Save as a model dedicated to inference\n",
    "model.save(\"keypoint_classifier.hdf5\", include_optimizer=False)\n"
   ],
   "id": "fc99762700fbeecc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-02T09:54:50.130002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert the model to TensorFlow Lite format with quantization\n",
    "tflite_save_path = 'hand_gesture_model.tflite'\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model\n",
    "with open(tflite_save_path, 'wb') as f:\n",
    "    f.write(tflite_quantized_model)\n"
   ],
   "id": "c8d7168400f4c9dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\sarpa\\AppData\\Local\\Temp\\tmp3o5w3lsw\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\sarpa\\AppData\\Local\\Temp\\tmp3o5w3lsw\\assets\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T09:50:55.526345Z",
     "start_time": "2024-07-02T09:50:55.444345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference test with TensorFlow Lite model\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensor details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Set the input tensors\n",
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_landmarks_test[0]]))\n",
    "interpreter.set_tensor(input_details[1]['index'], np.array([X_point_history_test[0]]))\n",
    "\n",
    "# Perform inference\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# Print results\n",
    "print(\"TFLite Model Results:\", np.squeeze(tflite_results))\n",
    "print(\"Predicted Class:\", np.argmax(np.squeeze(tflite_results)))\n"
   ],
   "id": "355a0cc9c46d9418",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tflite_save_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Inference test with TensorFlow Lite model\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m interpreter \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mlite\u001B[38;5;241m.\u001B[39mInterpreter(model_path\u001B[38;5;241m=\u001B[39m\u001B[43mtflite_save_path\u001B[49m)\n\u001B[0;32m      3\u001B[0m interpreter\u001B[38;5;241m.\u001B[39mallocate_tensors()\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Get input and output tensor details\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'tflite_save_path' is not defined"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d2732ec63e095201"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
